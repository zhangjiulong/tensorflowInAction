[data]
#train_feats = /asrDataCenter/dataCenter/asr/td/vx/binaryFormat/110h_traindata_txt/train2.csv
#train_labels = /asrDataCenter/dataCenter/asr/td/vx/binaryFormat/110h_traindata_txt/train2.label.csv
#dev_feats = /asrDataCenter/dataCenter/asr/td/vx/binaryFormat/110h_traindata_txt/cv2.csv
#dev_labels = /asrDataCenter/dataCenter/asr/td/vx/binaryFormat/110h_traindata_txt/cv2.label.csv

#train_feats = /home/zhangjl/aiGit/asr/src/mxnet/train2.test.csv
#train_labels = /home/zhangjl/aiGit/asr/src/mxnet/train2.test.label.csv
#dev_feats = /home/zhangjl/aiGit/asr/src/mxnet/train2.test.csv
#dev_labels = /home/zhangjl/aiGit/asr/src/mxnet/train2.test.label.csv

#train_feats = /home/zhangjl/aiGit/asr/src/mxnet/toy-ctc_feat.train.csv
#train_labels = /home/zhangjl/aiGit/asr/src/mxnet/toy-ctc_label.train.csv
#dev_feats = /home/zhangjl/aiGit/asr/src/mxnet/toy-ctc_feat.train.csv
#dev_labels = /home/zhangjl/aiGit/asr/src/mxnet/toy-ctc_label.train.csv

#train_feats = /asrDataCenter/dataCenter/asr/td/vx/binaryFormat/110h_traindata_txt/train2.csv
#train_labels = /asrDataCenter/dataCenter/asr/td/vx/binaryFormat/110h_traindata_txt/train2.label.csv
#dev_feats = /asrDataCenter/dataCenter/asr/td/vx/binaryFormat/110h_traindata_txt/cv2.csv
#dev_labels = /asrDataCenter/dataCenter/asr/td/vx/binaryFormat/110h_traindata_txt/cv2.label.csv

train_feats = /home/zhangjl/aiGit/asr/src/mxnet/data/train2_rm_long.csv
train_labels = /home/zhangjl/aiGit/asr/src/mxnet/data/train2.label_rm_long.csv
dev_feats = /home/zhangjl/aiGit/asr/src/mxnet/data/cv2_rm_long.csv
dev_labels = /home/zhangjl/aiGit/asr/src/mxnet/data/cv2.label_rm_long.csv

# label num means label seq len
label_num = 282
label_size = 90
frame_dim = 120
seq_len = 1667

[arch]
num_hidden = 320
num_lstm_layer = 3

[train]
#recordsNum4Train = 124024
recordsNum4Train = 100000
recordsNum4Test = 5000
#recordsNum4Test = 6989
batch_size = 20
num_epoch = 10

# gpu0, gpu1
context = gpu0
#context = gpu0, gpu2
#context = cpu0

# checkpoint prefix
prefix = asr001

learning_rate = 0.00004


################following is not used now###################
decay_factor = 2
decay_lower_bound = 1e-6

optimizer = speechSGD
momentum = 0.9

# set to 0 to disable gradient clipping
clip_gradient = 1

# uniform, normal, xavier
initializer = Uniform
init_scale = 0.05
weight_decay = 0.008

# show progress every how many batches
show_every = 1000
